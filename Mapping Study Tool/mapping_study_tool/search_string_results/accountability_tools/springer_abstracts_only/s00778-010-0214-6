                          <p class="Para">Data integration methods enable different data providers to flexibly integrate their expertise and deliver highly customizable services to their customers. Nonetheless, combining data from different sources could potentially reveal person-specific sensitive information. In VLDBJ 2006, Jiang and Clifton (Very Large Data Bases J (VLDBJ) 15(4):316â€“333, <span class="CitationRef"><a href="#CR24">2006</a></span>) propose a secure Distributed <em class="EmphasisTypeItalic ">k</em>-Anonymity (D<em class="EmphasisTypeItalic ">k</em>A) framework for integrating two private data tables to a <em class="EmphasisTypeItalic ">k</em>-anonymous table in which each private table is a vertical partition on the same set of records. Their proposed D<em class="EmphasisTypeItalic ">k</em>A framework is not scalable to large data sets. Moreover, D<em class="EmphasisTypeItalic ">k</em>A is limited to a two-party scenario and the parties are assumed to be semi-honest. In this paper, we propose two algorithms to securely integrate private data from multiple parties (data providers). Our first algorithm achieves the <em class="EmphasisTypeItalic ">k</em>-anonymity privacy model in a <em class="EmphasisTypeItalic ">semi-honest</em> adversary model. Our second algorithm employs a game-theoretic approach to thwart <em class="EmphasisTypeItalic ">malicious</em> participants and to ensure fair and honest participation of multiple data providers in the data integration process. Moreover, we study and resolve a real-life privacy problem in data sharing for the financial industry in Sweden. Experiments on the real-life data demonstrate that our proposed algorithms can effectively retain the essential information in anonymous data for data analysis and are scalable for anonymizing large data sets.</p>
