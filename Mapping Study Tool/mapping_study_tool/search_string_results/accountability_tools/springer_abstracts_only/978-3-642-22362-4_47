                          <p class="Para">Adaptation on public displays brings certain advantages and risks. Due to the implicit nature of adaptation, the users often miss the causality behind the adaptive behavior. Moreover, a high degree of autonomy in adaptive displays may leave the users with the feeling of control loss. Limited amount of transparency and controllability leads to the loss of user trust. As a result, the users feel insecure, frustrated, and are likely to abandon the system. The research goal of this work is to optimize the system actions in a ubiquitous display environment, in order make adaptation design transparent, controllable, and thus trustworthy. By means of a decision-theoretic approach the user trust can be assessed in different trust-critical contexts. The contexts describe the changes in the environment that call for adaptation: privacy of content, social setting, and accuracy of knowledge. The generated decisions enable the system to maintain trust and keep interaction comfortable.</p>
